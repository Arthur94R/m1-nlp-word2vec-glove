Projet GitHub : https://github.com/Arthur94R/m1-nlp-word2vec

# ğŸ¬ğŸ“± TP1 â€” Embeddings Word2Vec

Projet universitaire â€” Master 1 IA & Big Data, UniversitÃ© Paris 8

## ğŸ“‹ Description

CrÃ©ation et analyse d'embeddings Word2Vec sur deux datasets textuels :
- **Dataset 1** : 45 466 descriptions de films
- **Dataset 2** : 194 439 reviews Amazon d'accessoires tÃ©lÃ©phoniques

L'objectif est de comprendre comment Word2Vec capture le sens sÃ©mantique des mots en transformant du texte en vecteurs numÃ©riques.

## ğŸ¯ Objectif

DÃ©montrer que Word2Vec crÃ©e des reprÃ©sentations vectorielles qui capturent :
- La **similaritÃ© sÃ©mantique** (mots similaires â†’ vecteurs proches)
- Les **relations complexes** (analogies comme king - man + woman â‰ˆ queen)
- Le **contexte d'utilisation** des mots

## ğŸ” Ã‰tapes du TP

1. **Chargement et analyse** des datasets
2. **Preprocessing** : lowercase, tokenisation, suppression stop words
3. **RÃ©duction du vocabulaire** : min_count=5 pour garder les mots frÃ©quents
4. **EntraÃ®nement Word2Vec** : Skip-gram, 100 dimensions
5. **Analyse des embeddings** :
   - Mots similaires
   - Relations vectorielles
   - Visualisation des vecteurs

## ğŸ› ï¸ Stack technique

- **Python 3.13** â€” Langage principal
- **Gensim** â€” EntraÃ®nement Word2Vec
- **NLTK** â€” Tokenisation et stop words
- **Pandas / NumPy** â€” Traitement des donnÃ©es

## ğŸ“ Structure
```
data/              â†’ Datasets (Ã  tÃ©lÃ©charger)
src/
â”œâ”€â”€ main.py        â†’ Pipeline Word2Vec â€” films
â””â”€â”€ phones.py      â†’ Pipeline Word2Vec â€” reviews tÃ©lÃ©phones
results/           â†’ ModÃ¨les sauvegardÃ©s
```

## ğŸ“¥ RÃ©cupÃ©rer les donnÃ©es

**Datasets Ã  tÃ©lÃ©charger :**

1. **movies_metadata.csv** â†’ [Kaggle - The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset)
2. **Cell_Phones_and_Accessories_5.json** â†’ [Amazon Reviews](https://nijianmo.github.io/amazon/index.html)

Placer les fichiers dans le dossier `data/`.

**Fichiers gÃ©nÃ©rÃ©s automatiquement :**
- `word2vec_films.bin` â€” ModÃ¨le Word2Vec entraÃ®nÃ© sur les films
- `word2vec_phones.bin` â€” ModÃ¨le Word2Vec entraÃ®nÃ© sur les reviews

## ğŸš€ Installation et lancement

### Installation
```bash
# Installer les dÃ©pendances
pip install pandas numpy gensim nltk

# TÃ©lÃ©charger les ressources NLTK
python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt')"
```

### Lancement
```bash
# Pipeline films
python src/main.py

# Pipeline reviews tÃ©lÃ©phones
python src/phones.py
```

## ğŸ“Š RÃ©sultats attendus

### Mots similaires (dataset films)
```
'love' est proche de :
  affection    : 0.741
  romance      : 0.735
  madly        : 0.730

'action' est proche de :
  installment  : 0.808
  paced        : 0.786
  thriller     : 0.774
```

### Relations vectorielles
```
king - man + woman â‰ˆ princess, ruler, empress
```

### Vecteurs
Chaque mot = vecteur de 100 dimensions
```
'love' â†’ [0.084, 0.115, -0.090, -0.551, ...]
'hero' â†’ [0.462, -0.068, 0.424, -0.315, ...]
```

## ğŸ“ Livrables

- âœ… Code source (`main.py`, `phones.py`)
- âœ… ModÃ¨les Word2Vec entraÃ®nÃ©s
- âœ… Rapport PDF d'analyse
- âœ… README

## ğŸ“ Concepts clÃ©s

- **Word2Vec** : Algorithme de reprÃ©sentation textuelle (pas un modÃ¨le de prÃ©diction)
- **Skip-gram** : MÃ©thode qui prÃ©dit le contexte Ã  partir d'un mot
- **Embeddings** : ReprÃ©sentations vectorielles denses des mots
- **SimilaritÃ© cosinus** : Mesure de proximitÃ© entre vecteurs